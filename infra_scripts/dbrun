#!/usr/bin/env python
"""
DB Experiments Runner

Code Structure:
----------------
    - Constants & Parameters:

    - Main function:
        main()

    - Helper functions:
        build_pkgs(), build_pkg(), run_single_test()

    - Utility functions:
        report_cmd_msge(), show_options(), ensure_log_dir_exists(), animate()

    - Color codes and Custom Help Formatter:
        - Colors: ANSI color codes
        - ColorfulHelpFormatter: Custom Help Formatter
"""

import os
import subprocess
import argparse
import sys
import time

from utils import (
    collect_runtimes_from_client_logs,
    ColorfulHelpFormatter,
    Colors,
    ensure_log_dir_exists,
    animate,
    report_cmd_msge,
    show_options,
)

# --------------------- Constants & Parameters -------------------------------
DEFAULT_SEED = 42
IS_IN_DOCKER = os.path.exists("/.dockerenv")
BASE_DIR = (
    os.path.expanduser("~/workspace/h/classes/cs165/mainproj/code/proj/")
    if not IS_IN_DOCKER
    else "/cs165/"
)

# Path constants
DB_SRC_PATH = os.path.expanduser(f"{BASE_DIR}src/")
EXPERIMENTS_PATH = os.path.expanduser(f"{BASE_DIR}experiments/")
TEST_OUTPUT_PATH = os.path.expanduser(f"{BASE_DIR}test_output/")
DATA_GEN_SCRIPTS_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data_gen_scripts/")
GENERATED_DATA_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}generated_data/")
INFRA_SCRIPTS_PATH = os.path.expanduser(f"{BASE_DIR}infra_scripts/")

# Binary paths
SERVER_BINARY = os.path.expanduser(f"{DB_SRC_PATH}server")
CLIENT_BINARY = os.path.expanduser(f"{DB_SRC_PATH}client")

GEN_DATA_SCRIPT = os.path.expanduser(
    f"{BASE_DIR}project_tests/data_generation_scripts/"
)
GEN_M1_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone1.py")
GEN_M2_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone2.py")
GEN_M3_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone3.py")
GEN_M4_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone4.py")

TEST_MILESTONE_SCRIPT = os.path.expanduser(f"{INFRA_SCRIPTS_PATH}test_milestone.sh")

# File extensions and patterns
DSL_EXTENSION = ".dsl"
LOG_EXTENSION = ".log"
OUTPUT_EXTENSION = ".out"
ERROR_EXTENSION = ".err"
TIME_EXTENSION = ".time"

# Default values
DEFAULT_SEED = 42
SERVER_START_DELAY = 1
SERVER_SHUTDOWN_TIMEOUT = 5

# Experiment Queries Paths. These should be generated by the data generation
# scripts, if IN_EXPERIMENTS=True. see data_gen_scripts/milestone{1,2,3,4}.py
M1_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone1/")
M2_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone2/")
M3_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone3/")
M4_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone4/")


# Final parsed data and results paths
PARSED_M1_RESULTS_PATH = f"{BASE_DIR}/experiments/results/milestone1/"
PARSED_M2_RESULTS_PATH = f"{BASE_DIR}/experiments/results/milestone2/"
PARSED_M3_RESULTS_PATH = f"{BASE_DIR}/experiments/results/milestone3/"
PARSED_M4_RESULTS_PATH = f"{BASE_DIR}/experiments/results/milestone4/"

# if final results paths do not exist, create them
for path in [
    PARSED_M1_RESULTS_PATH,
    PARSED_M2_RESULTS_PATH,
    PARSED_M3_RESULTS_PATH,
    PARSED_M4_RESULTS_PATH,
]:
    if not os.path.exists(path):
        os.makedirs(path)


# ---------------------------- Main Function ---------------------------------
def main():
    parser = argparse.ArgumentParser(
        description="Run DB Experiments",
        formatter_class=ColorfulHelpFormatter,
    )

    parser.add_argument(
        "-b",
        "--build",
        action="store_true",
        help="Make the `server` and `client` executables",
    )
    parser.add_argument(
        "-t",
        "--test-milestone",
        action="store_true",
        help="Run tests for all milestone up to <m>",
    )

    parser.add_argument(
        "-e",
        "--run-experiment",
        action="store_true",
        help="Run experiments for milestone <m>",
    )

    run_mile_group = parser.add_argument_group("Additional Arguments")
    run_mile_group.add_argument(
        "-m",
        dest="mile_no",
        help="Milestone number",
    )

    args = parser.parse_args()

    if not any(vars(args).values()):
        parser.print_help()
        return

    if args.build and not build_pkg():
        sys.exit(1)

    if args.test_milestone:
        build_pkg(verbose=True)
        run_test_milestones(args.mile_no, verbose=True)
    elif args.run_experiment:
        build_pkg()
        # Needed to ensure necessary data are generated before running
        # experiments no need to do this if tests were run before, but if not,
        #  we need to generate data first (also ensure correctness)
        run_test_milestones(args.mile_no, verbose=False)
        run_milestone_experiment(args.mile_no)


# ---------------------------- Helper Functions ------------------------------


def run_piped_cmd(cmd, log_file_path, show_stdout=False):
    out, err = log_file_path + ".out", log_file_path + ".err"

    with open(out, "w", encoding="utf-8") as outfile, open(
        err, "w", encoding="utf-8"
    ) as errfile:
        additonal_info = {"stdout": out, "stderr": err}

        report_cmd_msge(cmd, additonal_info)

        if show_stdout:  # useful for development/debug to see real-time output
            process = subprocess.Popen(cmd.split(), stderr=errfile)
            process.wait()

        else:  # redirect stdout to file, mostly when running experiments
            process = subprocess.Popen(cmd.split(), stdout=outfile, stderr=errfile)
            animate()
            while process.poll() is None:
                animate()
            print(" Done!")

        return process


def build_pkg(pkg_path=DB_SRC_PATH, verbose=False):
    try:
        os.chdir(pkg_path)
    except OSError:
        print(f"Failed to change directory to {pkg_path}")
        return False

    log_dir = ensure_log_dir_exists(pkg_path)
    if not log_dir:
        return False

    log_file_path = os.path.join(EXPERIMENTS_PATH, "compile.log")
    process = run_piped_cmd("make", log_file_path, show_stdout=verbose)

    if process.returncode != 0:
        print(
            f"{Colors.RED} ❌ Build returned non-zero exit code:"
            f"{process.returncode}{Colors.ENDC}"
        )

        if os.path.exists(log_file_path):
            print("Showing the build log: ")
            subprocess.run(["cat", log_file_path])
            print(f"Full log file: {Colors.BLUE}{log_file_path}{Colors.ENDC}")

        return False  # Build failed

    print(f"{Colors.GREEN} ✅ BUILD SUCCEEDED {Colors.ENDC}\n\n")
    return True


def run_test_milestones(mile_no, verbose=False):
    # runs the TEST_MILESTONE_SCRIPT with the given milestone number
    print(f"Running tests for milestone up to {mile_no}")
    cmd = f"{TEST_MILESTONE_SCRIPT} {mile_no}"
    log_file_path = os.path.join(EXPERIMENTS_PATH, f"test_m{mile_no}.results")
    process = run_piped_cmd(cmd, log_file_path, show_stdout=verbose)

    return process.returncode == 0


def run_milestone_experiment(mile_no):
    if mile_no == "1":
        # Probably no need to run multiple trials,
        # m1 have about 10 select queries in each data size/run
        run_m1_experiment(n_trials=5)
    # elif mile_no == "2":
    #     run_m2_experiment()
    # elif mile_no == "3":
    #     run_m3_experiment()
    # elif mile_no == "4":
    #     run_m4_experiment()
    else:
        print(f"{Colors.RED}Invalid Milestone Number: {mile_no}{Colors.ENDC}")


def generate_data(mile_no, n, seed, data_dir, kwargs):
    """
    Args:
        mile_no: Milestone number
        n: Number of data points
        seed: Random seed
        data_dir: Directory to save the generated data
        kwargs: Additional arguments for the data generation script
                e.g., number of queries (k) for milestone 2 to batch, etc.
    """
    if mile_no == "1":
        gen_data_script = GEN_M1_DATA_PY
    elif mile_no == "2":
        gen_data_script = GEN_M2_DATA_PY
    elif mile_no == "3":
        gen_data_script = GEN_M3_DATA_PY
    elif mile_no == "4":
        gen_data_script = GEN_M4_DATA_PY
    else:
        print(f"{Colors.RED}Invalid Milestone Number: {mile_no}{Colors.ENDC}")
        return False

    cmd = f"python {gen_data_script}  {n} {seed}"

    run_piped_cmd(cmd, os.path.join(data_dir, f"gen_data_n={n}.log"))


def run_m1_experiment(n_trials=10):
    """
    Run milestone 1 experiments for different data sizes.

    After generating data in IN_EXPERIMENTS mode, M1_QUERIES_PATH should have
    the directories for different data sizes. For example, if n_start=2^10=1024
    and n_end=2^20=1048576, the M1_QUERIES_PATH should look like:
    ```
        .
        ├── 1024
        ├── 1048576
        ├── 131072
        ├── 16384
        ├── 2048
        ├── 262144
        ├── 32768
        ├── 4096
        ├── 524288
        ├── 65536
        └── 8192
    ```
    where each directory contains the DSL files for the queries to be run.

    Args:
        n_start: Starting data size
        n_end: Ending data size
        step_size: Increment size between experiments

    Returns:
        None, server logs with be stored in files named `server_run=<r>.log` in
            the same directory (M1_QUERIES_PATH/n) as the DSL files, where
            `r` is the r-th run.

    """
    print(
        f"{Colors.BOLD}Running Milestone 1 Experiments, n_trials={n_trials}...{Colors.ENDC}"
    )
    # run `./test_milestone.sh 01 5 1 <datasize` command
    delay = 5  # server's start up delay
    mile = 1

    for data_size in os.listdir(M1_QUERIES_PATH):
        for run in range(n_trials):
            print(f"data_size={data_size}, run={run}")
            cmd = f"{TEST_MILESTONE_SCRIPT} 01 {delay} {mile} {data_size}"
            log_file_path = os.path.join(M1_QUERIES_PATH, data_size, f"run={run}.log")

            process = run_piped_cmd(cmd, log_file_path)

            if process.returncode != 0:
                print(
                    f"{Colors.RED} ❌ Experiment returned non-zero exit code:"
                    f"{process.returncode}{Colors.ENDC}"
                )
                return False
            print(f"{Colors.GREEN} Experiment done! {Colors.ENDC}")
            print(f"parsing logs for data_size={data_size}, run={run}")
            time.sleep(1)

            parsed_file = PARSED_M1_RESULTS_PATH + f"n={data_size}run={run}.csv"
            collect_runtimes_from_client_logs(M1_QUERIES_PATH + data_size, parsed_file)
            print(
                f"{Colors.GREEN}Parsed logs can be found in {parsed_file}{Colors.ENDC}"
            )
    print(f"{Colors.GREEN}All milestone 1 experiments completed{Colors.ENDC}")


if __name__ == "__main__":
    main()
